{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import minimize, linprog\n",
    "from scipy.stats import ranksums, mannwhitneyu, rankdata\n",
    "import scipy.stats as stats\n",
    "\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, normalization = 'Linf'):\n",
    "    if normalization == 'Linf':\n",
    "        return data.apply(lambda x: x/max(x), axis=0)\n",
    "    elif normalization == 'L1':\n",
    "        return data.apply(lambda x: x/sum(x), axis=0)\n",
    "    elif normalization == 'L2':\n",
    "        return data.apply(lambda x: x/math.sqrt(sum(x ** 2)), axis=0)\n",
    "    elif normalization == 'maxmin':\n",
    "        return data.apply(lambda x: (x - min(x))/(max(x) - min(x)), axis=0)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(alternatives, criteria, perc_s, disparate_impact, normalization, seed = 2020):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # DATA\n",
    "    data = np.random.rand(alternatives, criteria) * np.random.uniform(low=0, high=10, size=criteria)\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    # WEIGHT\n",
    "    w = np.random.rand(criteria)\n",
    "    w /= sum(w)\n",
    "    \n",
    "    # SENSITIVE ATTRIBUTE\n",
    "    s = np.repeat(0, alternatives)\n",
    "    s[:round(alternatives*perc_s)] = 1\n",
    "    \n",
    "    # CORRECTION FOR DISPARATE IMPACT\n",
    "    utility = np.dot(normalize(data, normalization), w)\n",
    "    di = np.mean(utility[s == 1])/np.mean(utility[s == 0])\n",
    "    di = 1/di\n",
    "    \n",
    "    data.iloc[s==1, :] = data.iloc[s==1, :] * di * disparate_impact\n",
    "    \n",
    "    return [data, w, s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FaiRank_linear(data, w, s, delta = 0.8, tau = 0.1):\n",
    "    # GOAL FUNCTION\n",
    "    w_y = np.ones(len(w))\n",
    "    w_w = np.zeros(len(w))\n",
    "    \n",
    "    obj = np.concatenate((w_y, w_w), axis=None)\n",
    "    \n",
    "    # SUM OF WEIGHTS SHOULD BE ONE\n",
    "    lhs_eq = np.matrix(np.concatenate((np.zeros(len(w)), np.ones(len(w))), axis=None))\n",
    "    rh_e = [1]\n",
    "    \n",
    "    # ABSOLUTE VALUE IN THE GOAL FUNCTION\n",
    "    lhs_ineq_ind = (len(w), len(w)*2)\n",
    "    lhs_ineq_abs_l = np.zeros(lhs_ineq_ind)\n",
    "    \n",
    "    for i in range(lhs_ineq_abs_l.shape[0]):\n",
    "        lhs_ineq_abs_l[i, i] = 1\n",
    "        lhs_ineq_abs_l[i, len(w) + i] = -1\n",
    "        \n",
    "    rhs_ineq_abs_l = np.zeros(len(w))\n",
    "    \n",
    "    lhs_ineq_abs_h = np.zeros(lhs_ineq_ind)\n",
    "    \n",
    "    for i in range(lhs_ineq_abs_h.shape[0]):\n",
    "        lhs_ineq_abs_h[i, i] = -1\n",
    "        lhs_ineq_abs_h[i, len(w) + i] = -1\n",
    "    \n",
    "    rhs_ineq_abs_h = np.zeros(len(w))\n",
    "    \n",
    "    # DEMOGRAPHIC PARITY CONSTRAINT\n",
    "    s_adj = [delta * 1/(s == 0).sum() if x == 0 else -1 * 1/(s == 1).sum() for x in s]\n",
    "    \n",
    "    lhs_ineq_dp = np.concatenate((np.zeros(len(w)), np.dot(data.transpose(), s_adj)), axis=None)\n",
    "    rhs_ineq_dp = [0]\n",
    "    \n",
    "    # INDIVIDUAL FAIRNESS CONSTRAINT\n",
    "    lhs_ineq_ind = (data.shape[0], len(w)*2)\n",
    "    lhs_ineq_if_u = np.zeros(lhs_ineq_ind)\n",
    "    for i in range(lhs_ineq_if_u.shape[0]):\n",
    "        lhs_ineq_if_u[i, len(w):] = data.iloc[i, :]\n",
    "    \n",
    "    rhs_ineq_if_u = np.dot(data * (1 + tau), w)\n",
    "    \n",
    "    lhs_ineq_ind = (data.shape[0], len(w)*2)\n",
    "    lhs_ineq_if_l = np.zeros(lhs_ineq_ind)\n",
    "    for i in range(lhs_ineq_if_l.shape[0]):\n",
    "        lhs_ineq_if_l[i, len(w):] = -data.iloc[i, :]\n",
    "    \n",
    "    rhs_ineq_if_l = np.dot(data * (tau - 1), w)\n",
    "    \n",
    "    # COMBINING ALL\n",
    "    lhs_ineq = np.concatenate((lhs_ineq_abs_l, lhs_ineq_abs_h, np.vstack((lhs_ineq_dp, lhs_ineq_if_u, lhs_ineq_if_l))))\n",
    "    rhs_ineq = np.concatenate((rhs_ineq_abs_l, rhs_ineq_abs_h, rhs_ineq_dp, rhs_ineq_if_u, rhs_ineq_if_l))\n",
    "    \n",
    "    bnd = [(0, float(\"inf\"))] * len(w) * 2\n",
    "    opt = linprog(c=obj, \n",
    "                  A_ub=lhs_ineq, b_ub=rhs_ineq, \n",
    "                  A_eq=lhs_eq, b_eq=rh_e,\n",
    "                  bounds=bnd, method='interior-point')\n",
    "\n",
    "    return {'GoalFunction': opt.fun, 'Success': opt.success, 'Status': opt.status, \n",
    "            'Weights': opt.x[len(w):], 'Slack': opt.slack}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_analysis(utility_discriminated, utility_privileged):\n",
    "    mw_stat = mannwhitneyu(utility_discriminated, utility_privileged, alternative='two-sided')\n",
    "    wrs_stat = ranksums(utility_discriminated, utility_privileged)\n",
    "    \n",
    "    return {'Mann-Whitney-U': mw_stat.pvalue, 'Wilcoxon-RankSums': wrs_stat.pvalue}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_measure(utility_discriminated, utility_privileged):\n",
    "    di = np.mean(utility_discriminated)/np.mean(utility_privileged)\n",
    "    sp = np.mean(utility_discriminated) - np.mean(utility_privileged)\n",
    "    \n",
    "    return {'DI': di, 'SP': sp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, w, s = generate_data(10, 4, 0.4, 0.7, 'Linf', 2020)\n",
    "norm_data = normalize(data, 'Linf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0497231  0.11002766 0.44872918 0.39152006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GoalFunction': 1.765107421083979e-10,\n",
       " 'Success': True,\n",
       " 'Status': 0,\n",
       " 'Weights': array([0.39087918, 0.08525585, 0.26301638, 0.2608486 ]),\n",
       " 'Slack': array([3.90879181e-01, 8.52558458e-02, 2.63016376e-01, 2.60848597e-01,\n",
       "        3.90879181e-01, 8.52558461e-02, 2.63016376e-01, 2.60848597e-01,\n",
       "        1.58968676e-03, 6.99984591e-01, 8.73433400e-01, 7.32002036e-01,\n",
       "        1.18662088e+00, 9.89920272e-01, 2.31019168e+00, 7.18842075e-01,\n",
       "        2.46432360e+00, 3.21821798e+00, 1.85210486e+00, 1.11922863e+00,\n",
       "        3.20788693e-01, 9.89920357e-01, 7.85939281e-01, 2.93088492e-01,\n",
       "        1.17004417e+00, 7.69829622e-01, 1.02923595e-01, 2.00621669e-01,\n",
       "        7.92207742e-01])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FaiRank_linear(data, w, s, delta = 0.8, tau = 0.3)\n",
    "print(w)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DALJE NISAM DIRAO\n",
    "\n",
    "\n",
    "### EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_linear(alternatives, criteria, perc_s, disparate_impact, seed, normalization):\n",
    "    #GENERATE EXPERIMENT\n",
    "    data, w, s = generate_data(alternatives, criteria, perc_s, disparate_impact, normalization, seed)\n",
    "    norm_data = normalize(data, normalization)\n",
    "    \n",
    "    #PERFORM ANALYSIS\n",
    "    try:\n",
    "        model = FaiRank_linear_f(norm_data, w, s)\n",
    "        \n",
    "        #EVALUATE SOLUTION\n",
    "        utility_before = np.dot(norm_data, w)\n",
    "        utility_after = np.dot(norm_data, model['Weights'])\n",
    "        \n",
    "         # ovde ima sva≈°ta:\n",
    "        \n",
    "        w_dif = np.array(model['Weights'] - w)\n",
    "        count_neg_w_dif = sum(1 for number in w_dif if number < 0)\n",
    "        count_pos_w_dif = sum(1 for number in w_dif if number > 0)\n",
    "        count_0_w_dif = sum(1 for number in w_dif if number ==0)\n",
    "        perc_count_neg_w_dif = '{0:.2f}%'.format((count_neg_w_dif / (count_neg_w_dif + count_pos_w_dif + count_0_w_dif)  * 100))\n",
    "        perc_count_pos_w_dif = '{0:.2f}%'.format((count_pos_w_dif / (count_neg_w_dif + count_pos_w_dif + count_0_w_dif)  * 100))\n",
    "        perc_count_0_w_dif = '{0:.2f}%'.format((count_0_w_dif / (count_neg_w_dif + count_pos_w_dif + count_0_w_dif)  * 100))\n",
    "        \n",
    "        w_dif_abs = np.mean(abs(model['Weights'] - w))\n",
    "        \n",
    "        w_dif_max = max(list(model['Weights'] - w), key=abs)\n",
    "        w_dif_min = min(list(model['Weights'] - w), key=abs)\n",
    "        \n",
    "        utility_dif1 = np.array(utility_after[s==1] - utility_before[s==1])\n",
    "        count_neg_utility_dif1 = sum(1 for number in utility_dif1 if number < 0)\n",
    "        count_pos_utility_dif1 = sum(1 for number in utility_dif1 if number > 0)\n",
    "        count_0_utility_dif1 = sum(1 for number in utility_dif1 if number ==0)\n",
    "        perc_count_neg_utility_dif1 = '{0:.2f}%'.format((count_neg_utility_dif1 / (count_neg_utility_dif1 + count_pos_utility_dif1 + count_0_utility_dif1)  * 100))\n",
    "        perc_count_pos_utility_dif1 = '{0:.2f}%'.format((count_pos_utility_dif1 / (count_neg_utility_dif1 + count_pos_utility_dif1 + count_0_utility_dif1)  * 100))\n",
    "        perc_count_0_utility_dif1 = '{0:.2f}%'.format((count_0_utility_dif1 / (count_neg_utility_dif1 + count_pos_utility_dif1 + count_0_utility_dif1)  * 100))\n",
    "        \n",
    "        utility_dif0 = np.array(utility_after[s==0] - utility_before[s==0])\n",
    "        count_neg_utility_dif0 = sum(1 for number in utility_dif0 if number < 0)\n",
    "        count_pos_utility_dif0 = sum(1 for number in utility_dif0 if number > 0)\n",
    "        count_0_utility_dif0 = sum(1 for number in utility_dif0 if number ==0)\n",
    "        perc_count_neg_utility_dif0 = '{0:.2f}%'.format((count_neg_utility_dif0 / (count_neg_utility_dif0 + count_pos_utility_dif0 + count_0_utility_dif0)  * 100))\n",
    "        perc_count_pos_utility_dif0 = '{0:.2f}%'.format((count_pos_utility_dif0 / (count_neg_utility_dif0 + count_pos_utility_dif0 + count_0_utility_dif0)  * 100))\n",
    "        perc_count_0_utility_dif0 = '{0:.2f}%'.format((count_0_utility_dif0 / (count_neg_utility_dif0 + count_pos_utility_dif0 + count_0_utility_dif0)  * 100))\n",
    "        \n",
    "        # da bismo ispravili onu gre≈°ku, podelila sam sa du≈æinom, ali ovo treba proveriti\n",
    "        rank_abs_dif1 = np.mean(abs(rankdata([-utility_after[s==1]], method='min') / np.array(len(df_c[df_c['s'] == 1].index.tolist())) - rankdata([-utility_before[s==1]], method='min') / np.array(len(df_c[df_c['s'] == 1].index.tolist()))))\n",
    "        rank_abs_dif0 = np.mean(abs(rankdata([-utility_after[s==0]], method='min') / np.array(len(df_c[df_c['s'] == 0].index.tolist())) - rankdata([-utility_before[s==0]], method='min') / np.array(len(df_c[df_c['s'] == 0].index.tolist()))))\n",
    "            \n",
    "        utility_dif1_abs = np.mean(abs(utility_after[s==1] - utility_before[s==1]))\n",
    "        utility_dif0_abs = np.mean(abs(utility_after[s==0] - utility_before[s==0]))\n",
    "        \n",
    "        utility_dif_avg1 = np.mean(utility_after[s==1] - utility_before[s==1])\n",
    "        utility_dif_avg0 = np.mean(utility_after[s==0] - utility_before[s==0])\n",
    "        \n",
    "        utility_dif_max1 = max(list(utility_after[s==1] - utility_before[s==1]), key=abs)\n",
    "        utility_dif_max0 = max(list(utility_after[s==0] - utility_before[s==0]), key=abs)\n",
    "        \n",
    "        utility_dif_min1 = min(list(utility_after[s==1] - utility_before[s==1]), key=abs)\n",
    "        utility_dif_min0 = min(list(utility_after[s==0] - utility_before[s==0]), key=abs)\n",
    "\n",
    "        fairness_measures_before = fairness_measure(utility_before[s==1], utility_before[s==0])\n",
    "        fairness_measures_after = fairness_measure(utility_after[s==1], utility_after[s==0])\n",
    "\n",
    "        stat_measures_before = statistical_analysis(utility_before[s==1], utility_before[s==0])\n",
    "        stat_measures_after = statistical_analysis(utility_after[s==1], utility_after[s==0])\n",
    "        \n",
    "        # Nash bargaining solution\n",
    "        multiplicated_utility_before = np.multiply(utility_before)\n",
    "        multiplicated_utility_after = np.multiply(utility_after)\n",
    "    \n",
    "    except:\n",
    "        model = {'GoalFunction': 999, 'Success': False, 'Status': 0, 'Slack': 0, 'Weights': w}\n",
    "        \n",
    "        utility_before = {'Weighted_Sum_Before': 0}\n",
    "        utility_after = {'Weighted_Sum_After': 0}\n",
    "        \n",
    "        w_dif = {'Weight_Difference': 0}\n",
    "        count_neg_w_dif = {'Number_of_Negative_Weight_Differences': 0}\n",
    "        count_pos_w_dif = {'Number_of_Positive_Weight_Differences': 0}\n",
    "        count_0_w_dif = {'Number_of_Unchanged_Weight_Differences': 0}\n",
    "        perc_count_neg_w_dif = {'Percentage_of_Negative_Weight_Differences': 0}\n",
    "        perc_count_pos_w_dif = {'Percentage_of_Positive_Weight_Differences': 0}\n",
    "        perc_count_0_w_dif = {'Percentage_of_Unchanged_Weight_Differences': 0}\n",
    "        \n",
    "        w_dif_abs = {'Absolute_Weight_Difference': 0}\n",
    "        \n",
    "        w_dif_max = {'Max_Weight_Difference': 0}\n",
    "        w_dif_min = {'Min_Weight_Difference': 0}\n",
    "        \n",
    "        utility_dif1 = {'Weighted_Sum_Difference-Group1': 0}\n",
    "        count_neg_utility_dif1 = {'Number_of_Negative_Weighted_Sum_Differences-Group1': 0}\n",
    "        count_pos_utility_dif1 = {'Number_of_Positive_Weighted_Sum_Differences-Group1': 0}\n",
    "        count_0_utility_dif1 = {'Number_of_Unchanged_Weighted_Sum_Differences-Group1': 0}\n",
    "        perc_count_neg_utility_dif1 = {'Percentage_of_Negative_Weighted_Sum_Differences-Group1': 0}\n",
    "        perc_count_pos_utility_dif1 = {'Percentage_of_Positive_Weighted_Sum_Differences-Group1': 0}\n",
    "        perc_count_0_utility_dif1 = {'Percentage_of_Unchanged_Weighted_Sum_Differences-Group1': 0}\n",
    "        \n",
    "        utility_dif0 = {'Weighted_Sum_Difference-Group0': 0}\n",
    "        count_neg_utility_dif0 = {'Number_of_Negative_Weighted_Sum_Differences-Group0': 0}\n",
    "        count_pos_utility_dif0 = {'Number_of_Positive_Weighted_Sum_Differences-Group0': 0}\n",
    "        count_0_utility_dif0 = {'Number_of_Unchanged_Weighted_Sum_Differences-Group0': 0}\n",
    "        perc_count_neg_utility_dif0 = {'Percentage_of_Negative_Weighted_Sum_Differences-Group0': 0}\n",
    "        perc_count_pos_utility_dif0 = {'Percentage_of_Positive_Weighted_Sum_Differences-Group0': 0}\n",
    "        perc_count_0_utility_dif0 = {'Percentage_of_Unchanged_Weighted_Sum_Differences-Group0': 0}\n",
    "        \n",
    "        rank_abs_dif1 = {'Absolute_Rank_Difference-Group1': 0}\n",
    "        rank_abs_dif0 = {'Absolute_Rank_Difference-Group0': 0}\n",
    "            \n",
    "        utility_dif1_abs = {'Absolute_Difference-Weighted_Sum_Group1': 0}\n",
    "        utility_dif0_abs = {'Absolute_Difference-Weighted_Sum_Group0': 0}\n",
    "        \n",
    "        utility_dif_avg1 = {'Average_Difference-Weighted_Sum_Group1': 0}\n",
    "        utility_dif_avg0 = {'Average_Difference-Weighted_Sum_Group0': 0}\n",
    "        \n",
    "        utility_dif_max1 = {'Max_Difference-Weighted_Sum_Group1': 0}\n",
    "        utility_dif_max0 = {'Max_Difference-Weighted_Sum_Group0': 0}\n",
    "        \n",
    "        utility_dif_min1 = {'Min_Difference-Weighted_Sum_Group1': 0}\n",
    "        utility_dif_min0 = {'Min_Difference-Weighted_Sum_Group0': 0}\n",
    "        \n",
    "    \n",
    "        fairness_measures_before = {'DI': 0, 'SP': 0}\n",
    "        fairness_measures_after = {'DI': 0, 'SP': 0}\n",
    "        \n",
    "        stat_measures_before = {'Mann-Whitney-U': 0, 'Wilcoxon-RankSums': 0}\n",
    "        stat_measures_after = {'Mann-Whitney-U': 0, 'Wilcoxon-RankSums': 0}\n",
    "        \n",
    "        multiplicated_utility_before = {'Nash bargaining solution before': 0}\n",
    "        multiplicated_utility_after = {'Nash bargaining solution after': 0}\n",
    "    \n",
    "    return {'Type': 'Linear', 'Alternatives': alternatives, 'Criteria': criteria, 'Perc_S': perc_s, 'Normalization': normalization,\n",
    "            'GoalFunction': model['GoalFunction'], 'Success': model['Success'], \n",
    "            'Status': model['Status'], 'Slack': model['Slack'], \n",
    "            'Weight_Difference': w_dif,\n",
    "            'Number_of_Negative_Weight_Differences': count_neg_w_dif,\n",
    "            'Number_of_Positive_Weight_Differences': count_pos_w_dif,\n",
    "            'Number_of_Unchanged_Weight_Differences': count_0_w_dif,\n",
    "            'Percentage_of_Negative_Weight_Differences': perc_count_neg_w_dif,\n",
    "            'Percentage_of_Positive_Weight_Differences': perc_count_pos_w_dif,\n",
    "            'Percentage_of_Unchanged_Weight_Differences': perc_count_0_w_dif,\n",
    "            'Absolute_Weight_Difference': w_dif_abs,\n",
    "            'Max_Weight_Difference': w_dif_max, 'Min_Weight_Difference': w_dif_min,\n",
    "            'Weighted_Sum_Difference-Group1': utility_dif1,\n",
    "            'Number_of_Negative_Weighted_Sum_Differences-Group1': count_neg_utility_dif1,\n",
    "            'Number_of_Positive_Weighted_Sum_Differences-Group1': count_pos_utility_dif1,\n",
    "            'Number_of_Unchanged_Weighted_Sum_Differences-Group1': count_0_utility_dif1,\n",
    "            'Percentage_of_Negative_Weighted_Sum_Differences-Group1': perc_count_neg_utility_dif1,\n",
    "            'Percentage_of_Positive_Weighted_Sum_Differences-Group1': perc_count_pos_utility_dif1,\n",
    "            'Percentage_of_Unchanged_Weighted_Sum_Differences-Group1': perc_count_0_utility_dif1,\n",
    "            'Weighted_Sum_Difference-Group0': utility_dif0,\n",
    "            'Number_of_Negative_Weighted_Sum_Differences-Group0': count_neg_utility_dif0,\n",
    "            'Number_of_Positive_Weighted_Sum_Differences-Group0': count_pos_utility_dif0,\n",
    "            'Number_of_Unchanged_Weighted_Sum_Differences-Group0': count_0_utility_dif0,\n",
    "            'Percentage_of_Negative_Weighted_Sum_Differences-Group0': perc_count_neg_utility_dif0,\n",
    "            'Percentage_of_Positive_Weighted_Sum_Differences-Group0': perc_count_pos_utility_dif0,\n",
    "            'Percentage_of_Unchanged_Weighted_Sum_Differences-Group0': perc_count_0_utility_dif0,\n",
    "            'Absolute_Rank_Difference-Group1': rank_abs_dif1,\n",
    "            'Absolute_Rank_Difference-Group0': rank_abs_dif0,\n",
    "            'Absolute_Difference-Weighted_Sum_Group1': utility_dif1_abs, 'Absolute_Difference-Weighted_Sum_Group0': utility_dif0_abs,\n",
    "            'Average_Difference-Weighted_Sum_Group1': utility_dif_avg1, 'Average_Difference-Weighted_Sum_Group0': utility_dif_avg0,\n",
    "            'Max_Difference-Weighted_Sum_Group1': utility_dif_max1, 'Max_Difference-Weighted_Sum_Group0': utility_dif_max0,\n",
    "            'Min_Difference-Weighted_Sum_Group1': utility_dif_min1, 'Min_Difference-Weighted_Sum_Group0': utility_dif_min0,          \n",
    "            'DI-Before': fairness_measures_before['DI'], 'DI-After': fairness_measures_after['DI'], \n",
    "            'SP-Before': fairness_measures_before['SP'], 'SP-After': fairness_measures_after['SP'], \n",
    "            'MWU-Before': stat_measures_before['Mann-Whitney-U'], 'MWU-After': stat_measures_after['Mann-Whitney-U'], \n",
    "            'WRS-Before': stat_measures_before['Wilcoxon-RankSums'], 'WRS-After': stat_measures_after['Wilcoxon-RankSums'],\n",
    "            'Nash bargaining solution before': multiplicated_utility_before, 'Nash bargaining solution after': multiplicated_utility_after} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt = [6, 8, 10, 15, 20, 50, 100]\n",
    "crit = [3, 5, 7, 9]\n",
    "perc_s = [0.2, 0.3, 0.4]\n",
    "disp_imp = [0.4, 0.6, 0.8, 0.9]\n",
    "\n",
    "#\n",
    "norm = ['Linf', 'L1', 'L2','maxmin']\n",
    "seed = list(range(1, 101))\n",
    "\n",
    "results = []\n",
    "\n",
    "for a, c, p, d, s, n in itertools.product(alt, crit, perc_s, disp_imp, seed, norm):\n",
    "    print(a, c, p, d, s, n)\n",
    "    results.append(experiment_square(a, c, p, d, s, n))\n",
    "    results.append(experiment_linear(a, c, p, d, s, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('initial_experiments_8.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
